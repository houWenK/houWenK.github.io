<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Deepfm模型解析 | houWenk's Blog</title><meta name="author" content="houWenk"><meta name="copyright" content="houWenk"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Deepfm模型解析简介对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。但是现存的方法总是忽视了高阶或低阶组合特征的联系，或者要求专门的特征工程，因此建立了DeepFM模型，将FM与DNN结合起来。 模型演变和各模型间的对比CTR的任务要求CTR的数据特点1、输入中包含类别型和连续型数">
<meta property="og:type" content="article">
<meta property="og:title" content="Deepfm模型解析">
<meta property="og:url" content="http://houwenke.top/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/index.html">
<meta property="og:site_name" content="houWenk&#39;s Blog">
<meta property="og:description" content="Deepfm模型解析简介对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。但是现存的方法总是忽视了高阶或低阶组合特征的联系，或者要求专门的特征工程，因此建立了DeepFM模型，将FM与DNN结合起来。 模型演变和各模型间的对比CTR的任务要求CTR的数据特点1、输入中包含类别型和连续型数">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://houwenke.top/medias/page6.jpg">
<meta property="article:published_time" content="2023-07-19T02:09:57.107Z">
<meta property="article:modified_time" content="2024-04-18T08:20:57.629Z">
<meta property="article:author" content="houWenk">
<meta property="article:tag" content="Deepfm">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://houwenke.top/medias/page6.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://houwenke.top/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Deepfm模型解析',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-18 16:20:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"> <link rel="stylesheet" href="/css/myStyle.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div><div class="menus_item"><a class="site-page" href="/support/"><i class="fa-fw fas fa-support-copy"></i><span> 支持作者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/medias/page6.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="houWenk's Blog"><span class="site-name">houWenk's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div><div class="menus_item"><a class="site-page" href="/support/"><i class="fa-fw fas fa-support-copy"></i><span> 支持作者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Deepfm模型解析</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-19T02:09:57.107Z" title="发表于 2023-07-19 10:09:57">2023-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-18T08:20:57.629Z" title="更新于 2024-04-18 16:20:57">2024-04-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Deepfm模型解析"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Deepfm模型解析"><a href="#Deepfm模型解析" class="headerlink" title="Deepfm模型解析"></a>Deepfm模型解析</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。但是现存的方法总是忽视了高阶或低阶组合特征的联系，或者要求专门的特征工程，因此建立了DeepFM模型，将FM与DNN结合起来。</p>
<h2 id="模型演变和各模型间的对比"><a href="#模型演变和各模型间的对比" class="headerlink" title="模型演变和各模型间的对比"></a>模型演变和各模型间的对比</h2><h3 id="CTR的任务要求"><a href="#CTR的任务要求" class="headerlink" title="CTR的任务要求"></a>CTR的任务要求</h3><h4 id="CTR的数据特点"><a href="#CTR的数据特点" class="headerlink" title="CTR的数据特点"></a>CTR的数据特点</h4><p>1、输入中包含类别型和连续型数据。类别型数据需要one-hot,连续型数据可以先离散化再one-hot，也可以直接保留原值</p>
<p>2、维度非常高且数据非常稀疏</p>
<h4 id="CTR的预估重点"><a href="#CTR的预估重点" class="headerlink" title="CTR的预估重点"></a>CTR的预估重点</h4><p>CTR预估重点在于学习组合特征。<br>其中，组合特征包括二阶、三阶甚至更高阶的，阶数越高越复杂，越不容易学习。Google的论文研究得出结论：高阶和低阶的组合特征都非常重要，同时学习到这两种组合特征的性能要比只考虑其中一种的性能要好。</p>
<p>那么关键问题转化成：如何高效的提取这些组合特征。<br>一种办法就是引入领域知识人工进行特征工程。这样做的弊端是高阶组合特征非常难提取，会耗费极大的人力。而且，有些组合特征是隐藏在数据中的，即使是专家也不一定能提取出来，比如著名的“尿布与啤酒”问题。</p>
<h3 id="DeepFM模型的引入"><a href="#DeepFM模型的引入" class="headerlink" title="DeepFM模型的引入"></a>DeepFM模型的引入</h3><p>为了解决上文提到的提取组合特征的问题，该论文作者借鉴了Google的wide &amp; deep的做法提出了DeepFM模型。</p>
<p>DeepFM模型本质是<br>1、将Wide &amp; Deep 部分的wide部分由 人工特征工程+LR 转换为FM模型，避开了人工特征工程；<br>2、FM模型与deep part共享feature embedding。</p>
<p>Q1、为什么要用FM代替线性部分（wide）呢？<br>因为线性模型有个致命的缺点：无法提取高阶的组合特征。<br>FM通过隐向量latent vector做内积来表示组合特征，从理论上解决了低阶和高阶组合特征提取的问题。但是实际应用中受限于计算复杂度，一般也就只考虑到2阶交叉特征。</p>
<h3 id="各模型间的对比"><a href="#各模型间的对比" class="headerlink" title="各模型间的对比"></a>各模型间的对比</h3><p>1、随着DNN在图像、语音、NLP等领域取得突破，人们意识到DNN在特征表示上的天然优势。相继提出了使用CNN或RNN来做CTR预估的模型。但是，CNN模型的缺点是：偏向于学习相邻特征的组合特征。RNN模型的缺点是：比较适用于有序列(时序)关系的数据。</p>
<p>2、FNN (Factorization-machine supported Neural Network) 的提出，应该算是一次非常不错的尝试：先使用预先训练好的FM，得到隐向量，然后作为DNN的输入来训练模型。缺点在于：受限于FM预训练的效果。</p>
<p>3、PNN (Product-based Neural Network)，PNN为了捕获高阶组合特征，在embedding layer和first hidden layer之间增加了一个product layer。根据product layer使用内积、外积、混合分别衍生出IPNN, OPNN, PNN*三种类型。无论是FNN还是PNN，他们都有一个绕不过去的缺点：<strong>对于低阶的组合特征，学习到的比较少。</strong>而前面我们说过，低阶特征对于CTR也是非常重要的。</p>
<p>4、为了同时学习低阶和高阶组合特征，Google提出了Wide&amp;Deep模型。它混合了一个线性模型（Wide part）和Deep模型(Deep part)。这两部分模型需要不同的输入，而Wide part部分的输入，依旧依赖人工特征工程。</p>
<h3 id="DeepFM优势"><a href="#DeepFM优势" class="headerlink" title="DeepFM优势"></a>DeepFM优势</h3><p>3中的这些模型普遍都存在两个问题：<br>偏向于提取低阶或者高阶的组合特征。不能同时提取这两种类型的特征。<br>需要专业的领域知识来做特征工程。</p>
<p>DeepFM在Wide&amp;Deep的基础上进行改进，成功解决了这两个问题，并做了一些改进，其优势如下：<br>1.不需要预训练FM得到隐向量<br>2.不需要人工特征工程<br>3.能同时学习低阶和高阶的组合特征<br>4.FM模块和Deep模块共享Feature Embedding部分，可以更快的训练，以及更精确的训练学习</p>
<h2 id="Deepfm模型介绍"><a href="#Deepfm模型介绍" class="headerlink" title="Deepfm模型介绍"></a>Deepfm模型介绍</h2><img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/image-20210322193940693.png" class="">

<h3 id="Sparse-Feature部分"><a href="#Sparse-Feature部分" class="headerlink" title="Sparse Feature部分"></a>Sparse Feature部分</h3><p>Sparse Feature是指离散型变量。比如现在我有数据：xx公司每个员工的姓名、年龄、岗位、收入的表格，那么年龄和岗位就属于离散型变量，而收入则称为连续型变量。这从字面意思也能够理解。</p>
<p>现在Sparse Feature里表示的是将每个特征经过<strong>one-hot编码</strong>后拼接在一起的<strong>稀疏长向量</strong>，黄色的点表示某对象在该特征的取值中属于该位置的值。</p>
<h3 id="Dense-Embedding部分"><a href="#Dense-Embedding部分" class="headerlink" title="Dense Embedding部分"></a>Dense Embedding部分</h3><p><a target="_blank" rel="noopener" href="https://www.featureform.com/post/the-definitive-guide-to-embeddings">Embeddings in Machine Learning: Everything You Need to Know | FeatureForm</a></p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>这个长长的向量只有0，1两种取值，并且非常稀疏，如果直接采用权重去加和，将会丢失很多权重，这样会造成最终结果不准确。所以，得想个办法把这个稀疏向量变得稠密一些。在机器学习中关于对离散值的数据预处理有很多种方式，常见的有数据分箱、嵌入向量等，这个Dense Embedding就是指的将离散型变量嵌入为连续型变量。什么意思呢？</p>
<p>还是上面说的那个表格，比如年龄共有50个去重数值，岗位有100个去重数值，现在是两个特征。那么经过Embedding之后，年龄就变为了50 x m的矩阵，岗位就变成了100 x m的矩阵，这个m是指嵌入向量的维数，一般取4、8、16。下面的图示可能会比较直观一些：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/table1.png" class="">

<p>最终表格就变成了这样：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/table2.png" class="">

<p>也就是说，最终入模的数据表长这样：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/table3.png" class="">

<p>比如“漩涡鸣人”的特征向量可能就是这样的：</p>
<p>(x1,x2,…,xm,x1,x2,…,xm,…,···,x1,x2,…,xn)</p>
<p>x1,x2,…,xm 表示他的年龄的Embedding向量，x1,x2,…,xm 表示他的岗位的Embedding向量，… 表示他的其他属性的Embedding向量，x1,x2,…,xn 表示他的收入等其他连续型特征的归一化或标准化后的值。</p>
<p>一句话，就是拼接起来。</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">embedding = tf.constant(</span><br><span class="line">        [[0.21,0.41,0.51,0.11]],</span><br><span class="line">        [0.22,0.42,0.52,0.12],</span><br><span class="line">        [0.23,0.43,0.53,0.13],</span><br><span class="line">        [0.24,0.44,0.54,0.14]],dtype=tf.float32)</span><br><span class="line"> </span><br><span class="line">feature_batch = tf.constant([2,3,1,0])</span><br><span class="line"> </span><br><span class="line">get_embedding1 = tf.nn.embedding_lookup(embedding,feature_batch)</span><br></pre></td></tr></table></figure>

<p>在embedding_lookup中，第一个参数相当于一个二维的词表，并根据第二个参数中指定的索引，去词表中寻找并返回对应的行。上面的过程为：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/2019062919282518.png" class="">

<p>注意这里的维度的变化，假设我们的feature_batch 是 1维的tensor，长度为4，而embedding的长度为4，那么得到的结果是 4 * 4 的，同理，假设feature_batch是2 *4的，embedding_lookup后的结果是2 * 4 * 4。</p>
<p>embedding层其实是一个全连接神经网络层，那么其过程等价于：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/640.jpg" class="">

<p>可以得到下面的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">embedding = tf.constant(  </span><br><span class="line">        [[0.21,0.41,0.51,0.11],   </span><br><span class="line">		[0.22,0.42,0.52,0.12],       </span><br><span class="line">		[0.23,0.43,0.53,0.13],      </span><br><span class="line">		[0.24,0.44,0.54,0.14]],dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">feature_batch = tf.constant([2,3,1,0])</span><br><span class="line">feature_batch_one_hot = tf.one_hot(feature_batch,depth=4)</span><br><span class="line">get_embedding2 = tf.matmul(feature_batch_one_hot,embedding)</span><br></pre></td></tr></table></figure>

<p>二者是否一致呢？我们通过代码来验证一下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:    </span><br><span class="line">sess.run(tf.global_variables_initializer())   </span><br><span class="line">embedding1,embedding2 = sess.run([get_embedding1,get_embedding2])    </span><br><span class="line">print(embedding1)    </span><br><span class="line">print(embedding2)</span><br></pre></td></tr></table></figure>

<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/640.png" class="">

<p>二者得到的结果是一致的。</p>
<p>因此，使用embedding_lookup的话，我们不需要将数据转换为one-hot形式，只需要传入对应的feature的index即可。</p>
<h3 id="FM-Layer部分"><a href="#FM-Layer部分" class="headerlink" title="FM Layer部分"></a>FM Layer部分</h3><img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20201225093533807.png" class="">

<p>主要公式：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20210520000032809.png" class="">

<p>FM的公式，以及二次项的化简过程：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20200414142326593.png" class="">

<p>对于二次项，经过化简之后有两部分（暂不考虑最外层的求和），我们先用excel来形象展示一下两部分，这有助于你对下面代码的理解。</p>
<p>第一部分过程如下：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/6401.jpg" class="">

<p>第二部分的过程如下：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/6402.jpg" class="">

<p>最后两部分相减：</p>
<img src="Deepfm模型解析/6403.jpg" style="zoom:100%;" />

<p>转换完变成以下公式：</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20210524112219496.png" class="">

<h3 id="Hidden-Layer部分"><a href="#Hidden-Layer部分" class="headerlink" title="Hidden Layer部分"></a>Hidden Layer部分</h3><img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20201225093914850.png" class="">

<p>Deep Component是用来学习高阶组合特征的。网络里面黑色的线是全连接层，参数需要神经网络去学习。</p>
<p>Deep部分很简单了，就是几层全连接的神经网络：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;deep part&quot;&quot;&quot;</span><br><span class="line">y_deep = tf.reshape(embeddings,shape=[-1,dfm_params[&#x27;field_size&#x27;] * dfm_params[&#x27;embedding_size&#x27;]])</span><br><span class="line">for i in range(0,len(dfm_params[&#x27;deep_layers&#x27;])):</span><br><span class="line">    y_deep = tf.add(tf.matmul(y_deep,weights[&quot;layer_%d&quot; %i]), weights[&quot;bias_%d&quot;%I])</span><br><span class="line">    y_deep = tf.nn.relu(y_deep)</span><br></pre></td></tr></table></figure>

<h3 id="Outputs-Units部分"><a href="#Outputs-Units部分" class="headerlink" title="Outputs Units部分"></a>Outputs Units部分</h3><p>对象的特征先经过one-hot编码变为稀疏长向量，再通过Embedding变为统一长度的稠密向量，然后在FM结构中显示交互作用，以及在DNN结构中隐式交互作用，最后水到渠成就该输出预测目标值了。即：</p>
<p>如果是分类任务，那么就将两者的值相加再输入Sigmoid函数输出类别概率大小。</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/6d85124fe70be87665d960eb273dc8ba.png" class="">

<p>如果是回归任务，那么就直接将两者的值相加。</p>
<h2 id="核心的计算过程"><a href="#核心的计算过程" class="headerlink" title="核心的计算过程"></a>核心的计算过程</h2><p> （1）首先进行样本embedding结果的获取，针对每个样本，会根据其具有的特征索引列表feat_index，获取这些特征对应在weights[‘feature_embeddings’] 矩阵中所存储的embeding表达形式。之后我们样本原值， 利用embeding表达形式【维度 是 field长度 * embeding长度】 * 样本原值【维度是field长度】 得到当前样本的 embedding转换结果 【维度是 field长度 * embeding长度】，这里样本的特征长度都是field长度，权重矩阵中的特征长度则是feature_size。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.embeddings =tf.nn.embedding_lookup(self.weights[&#x27;feature_embeddings&#x27;],self.feat_index)  # N * F * K</span><br><span class="line">feat_value = tf.reshape(self.feat_value,shape=[-1,self.field_size,1])</span><br><span class="line">self.embeddings = tf.multiply(self.embeddings,feat_value)</span><br></pre></td></tr></table></figure>


<p>（2）进行FM部分的计算，FM部分可以分为一阶计算 和 二阶计算两部分。首先是一阶计算阶段， 其直接使用W *x计算结果即可，没做embeding.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.y_first_order = tf.nn.embedding_lookup(self.weights[&#x27;feature_bias&#x27;],self.feat_index)</span><br><span class="line">self.y_first_order = tf.reduce_sum(tf.multiply(self.y_first_order,feat_value),2)</span><br><span class="line">self.y_first_order = tf.nn.dropout(self.y_first_order,self.dropout_keep_fm[0])</span><br></pre></td></tr></table></figure>

<p>在二阶计算部分，对应如下的对FM转化的公式（优化后公式简单相当多），这里的u其实就是weights[‘feature_embeddings’]隐向量矩阵，u*x已经在第一部分做embedding时候做过了，剩余的就是 对两两内积结果的组内相加等操作</p>
<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20200414142326593.png" class="">

<p>对应代码如下，每个样本都是对应下面的过程，两部分的相减。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#second order term         这整体区间代表FM公式中的二次项计算</span><br><span class="line">#sum-square-part   在公式中 相减的前一部分。  先加后平方   这里的1表示维度内相加，对应公式中的，对所有的u*x的结果相加</span><br><span class="line">self.summed_features_emb = tf.reduce_sum(self.embeddings,1) # None * k</span><br><span class="line">self.summed_features_emb_square = tf.square(self.summed_features_emb) # None * K</span><br><span class="line">#squre-sum-part  在公式中 相减的后一部分。  先平方后加</span><br><span class="line">self.squared_features_emb = tf.square(self.embeddings)</span><br><span class="line">self.squared_sum_features_emb = tf.reduce_sum(self.squared_features_emb, 1)  # None * K</span><br><span class="line">#second order</span><br><span class="line">self.y_second_order =0.5*tf.subtract(self.summed_features_emb_square,self.squared_sum_features_emb)</span><br><span class="line">self.y_second_order = tf.nn.dropout(self.y_second_order,self.dropout_keep_fm[1])</span><br></pre></td></tr></table></figure>


<p>（3）最后是深度deep计算，这部分就是典型的DNN的方式，从embedidng结果开始【尺寸是field_size * embedding_size】，定义几层全连接计算即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Deep component     将Embedding part的输出再经过几层全链接层</span><br><span class="line"></span><br><span class="line">self.y_deep = tf.reshape(self.embeddings,shape=[-1,self.field_size * self.embedding_size])</span><br><span class="line">self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[0])</span><br><span class="line"></span><br><span class="line">for i in range(0,len(self.deep_layers)):</span><br><span class="line">   self.y_deep = tf.add(tf.matmul(self.y_deep,self.weights[&quot;layer_%d&quot; %i]), self.weights[&quot;bias_%d&quot;%i])</span><br><span class="line">   self.y_deep = self.deep_layers_activation(self.y_deep)</span><br><span class="line">   self.y_deep = tf.nn.dropout(self.y_deep,self.dropout_keep_deep[i+1])</span><br></pre></td></tr></table></figure>


<p>至此已经完成了核心的计算过程。</p>
<h2 id="模型效果对比"><a href="#模型效果对比" class="headerlink" title="模型效果对比"></a>模型效果对比</h2><img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20181226155135590.png" class="">

<img src="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/20181226154846920.png" class="">

<h2 id="其它说明"><a href="#其它说明" class="headerlink" title="其它说明"></a>其它说明</h2><p>文档：<a href="https://houwenke.top/">https://houwenke.top</a></p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/houWenK/recommend-model">https://github.com/houWenK/recommend-model</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://houwenke.top">houWenk</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://houwenke.top/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/">http://houwenke.top/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://houwenke.top" target="_blank">houWenk's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deepfm/">Deepfm</a></div><div class="post_share"><div class="social-share" data-image="/medias/page6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/04/15/python%E8%A3%85%E9%A5%B0%E5%99%A8/" title="python装饰器"><img class="cover" src="/medias/page9.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">python装饰器</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/17/YOLOv5%E7%9A%84Android%E9%83%A8%E7%BD%B2%EF%BC%8C%E5%9F%BA%E4%BA%8ENCNN/" title="YOLOv5的Android部署，基于NCNN"><img class="cover" src="/medias/page7.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">YOLOv5的Android部署，基于NCNN</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">houWenk</div><div class="author-info__description">路漫漫其修远兮，吾将上下而求索</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://gitee.com/houwenke1" target="_blank" title="Gitee"><i class="iconfont icon-gitee"></i></a><a class="social-icon" href="https://github.com/houWenK" target="_blank" title="Github"><i class="iconfont icon-github1"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_40625979?type=blog" target="_blank" title="CSDN"><i class="iconfont icon-csdn"></i></a><a class="social-icon" href="https://space.bilibili.com/290536875?spm_id_from=333.788.0.0" target="_blank" title="bilibili"><i class="iconfont icon-bilibili1"></i></a><a class="social-icon" href="mailto:454305202@qq.com" target="_blank" title="邮箱"><i class="iconfont icon-youxiang"></i></a><a class="social-icon" href="tencent://message/?uin=2105095848&amp;Site=Sambow&amp;Menu=yes" target="_blank" title="QQ"><i class="iconfont icon-qq"></i></a><a class="social-icon" href="https://weibo.com/u/5362865500" target="_blank" title="微博"><i class="iconfont icon-microblog"></i></a><a class="social-icon" href="https://tieba.baidu.com/home/main?id=tb.1.8344362b.UPVOjj5jkQ1TmQCsREcPMw?t=1511057048&amp;fr=index" target="_blank" title="百度贴吧"><i class="iconfont icon-baidu"></i></a><a class="social-icon" href="https://www.zhihu.com/people/chou-xiao-zi-17-58" target="_blank" title="知乎"><i class="iconfont icon-zhihu"></i></a><a class="social-icon" href="https://v.douyin.com/BEUu7w1/" target="_blank" title="抖音"><i class="iconfont icon-douyin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">作者邮箱：454305202@qq.com</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">Deepfm模型解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%BC%94%E5%8F%98%E5%92%8C%E5%90%84%E6%A8%A1%E5%9E%8B%E9%97%B4%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.2.</span> <span class="toc-text">模型演变和各模型间的对比</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CTR%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%A6%81%E6%B1%82"><span class="toc-number">1.2.1.</span> <span class="toc-text">CTR的任务要求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#CTR%E7%9A%84%E6%95%B0%E6%8D%AE%E7%89%B9%E7%82%B9"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">CTR的数据特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CTR%E7%9A%84%E9%A2%84%E4%BC%B0%E9%87%8D%E7%82%B9"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">CTR的预估重点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepFM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BC%95%E5%85%A5"><span class="toc-number">1.2.2.</span> <span class="toc-text">DeepFM模型的引入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%84%E6%A8%A1%E5%9E%8B%E9%97%B4%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.2.3.</span> <span class="toc-text">各模型间的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepFM%E4%BC%98%E5%8A%BF"><span class="toc-number">1.2.4.</span> <span class="toc-text">DeepFM优势</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deepfm%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.3.</span> <span class="toc-text">Deepfm模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sparse-Feature%E9%83%A8%E5%88%86"><span class="toc-number">1.3.1.</span> <span class="toc-text">Sparse Feature部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dense-Embedding%E9%83%A8%E5%88%86"><span class="toc-number">1.3.2.</span> <span class="toc-text">Dense Embedding部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FM-Layer%E9%83%A8%E5%88%86"><span class="toc-number">1.3.3.</span> <span class="toc-text">FM Layer部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hidden-Layer%E9%83%A8%E5%88%86"><span class="toc-number">1.3.4.</span> <span class="toc-text">Hidden Layer部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Outputs-Units%E9%83%A8%E5%88%86"><span class="toc-number">1.3.5.</span> <span class="toc-text">Outputs Units部分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">1.4.</span> <span class="toc-text">核心的计算过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.</span> <span class="toc-text">模型效果对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E5%AE%83%E8%AF%B4%E6%98%8E"><span class="toc-number">1.6.</span> <span class="toc-text">其它说明</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/11/17/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE/" title="秒杀项目"><img src="/medias/page8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="秒杀项目"/></a><div class="content"><a class="title" href="/2024/11/17/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE/" title="秒杀项目">秒杀项目</a><time datetime="2024-11-17T08:28:25.852Z" title="发表于 2024-11-17 16:28:25">2024-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/18/ADB%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="uiautomator2笔记"><img src="/medias/page9.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="uiautomator2笔记"/></a><div class="content"><a class="title" href="/2024/04/18/ADB%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="uiautomator2笔记">uiautomator2笔记</a><time datetime="2024-04-18T07:38:50.192Z" title="发表于 2024-04-18 15:38:50">2024-04-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/15/python%E8%A3%85%E9%A5%B0%E5%99%A8/" title="python装饰器"><img src="/medias/page9.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python装饰器"/></a><div class="content"><a class="title" href="/2024/04/15/python%E8%A3%85%E9%A5%B0%E5%99%A8/" title="python装饰器">python装饰器</a><time datetime="2024-04-15T07:47:07.356Z" title="发表于 2024-04-15 15:47:07">2024-04-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/" title="Deepfm模型解析"><img src="/medias/page6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Deepfm模型解析"/></a><div class="content"><a class="title" href="/2023/07/19/Deepfm%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/" title="Deepfm模型解析">Deepfm模型解析</a><time datetime="2023-07-19T02:09:57.107Z" title="发表于 2023-07-19 10:09:57">2023-07-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/17/YOLOv5%E7%9A%84Android%E9%83%A8%E7%BD%B2%EF%BC%8C%E5%9F%BA%E4%BA%8ENCNN/" title="YOLOv5的Android部署，基于NCNN"><img src="/medias/page7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="YOLOv5的Android部署，基于NCNN"/></a><div class="content"><a class="title" href="/2023/03/17/YOLOv5%E7%9A%84Android%E9%83%A8%E7%BD%B2%EF%BC%8C%E5%9F%BA%E4%BA%8ENCNN/" title="YOLOv5的Android部署，基于NCNN">YOLOv5的Android部署，基于NCNN</a><time datetime="2023-03-17T06:52:04.000Z" title="发表于 2023-03-17 14:52:04">2023-03-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By houWenk</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script defer src="/live2d-widget-master/autoload.js"></script> <script src="/js/jquery.js"></script> <script src="/js/foot.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>